{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision and Deep Learning \n",
    "## Lab 3 - Feature Descriptors\n",
    "This lab looks into common feature extractors in the vision community. We will look at various filters on static images, and the use of cascade detectors in detection within video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "The following section defines the imports used for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-33f83e9f1487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# For image processing applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# For ndarray handling:\n",
    "import numpy as np\n",
    "\n",
    "# For plotting:\n",
    "#%matplotlib notebook\n",
    "#%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = [11,11]\n",
    "\n",
    "# For image processing applications\n",
    "import cv2\n",
    "import skimage.io\n",
    "import skimage.feature\n",
    "import scipy.signal\n",
    "\n",
    "# For saving images\n",
    "import skimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vase.jpg image\n",
    "We will use a basic image to look at the various filtering operations, but feel free to substitute in your own. Try more complex image structures, do they all work well on noisy images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread('vase.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the kernel ourselves\n",
    "LoG_filter = np.asarray([[0,  0,   1,  0,  0],\n",
    "                         [0,  1,   2,  1,  0],\n",
    "                         [1,  2, -16,  2,  1],\n",
    "                         [0,  1,   2,  1,  0],\n",
    "                         [0,  0,   1,  0,  0]])\n",
    "\n",
    "# Do the convolution\n",
    "convolution_result = scipy.signal.convolve2d(skimage.color.rgb2gray(image), LoG_filter, mode='valid')\n",
    "\n",
    "# Plot the resulting output\n",
    "plt.figure()\n",
    "plt.imshow(convolution_result)\n",
    "plt.show()\n",
    "\n",
    "# This is interesting. Why?\n",
    "print(image.shape)\n",
    "print(convolution_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prewitt Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the image with a Prewitt filter\n",
    "image_prewitt = skimage.filters.prewitt(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_prewitt, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_prewitt <= skimage.filters.threshold_otsu(image_prewitt), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the image with a Sobel filter\n",
    "image_sobel = skimage.filters.sobel(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_sobel, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_sobel <= skimage.filters.threshold_otsu(image_sobel), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the horizontal and vertical Sobel's seperately\n",
    "image_sobel = skimage.filters.sobel(skimage.color.rgb2gray(image))\n",
    "image_sobel_h = skimage.filters.sobel_h(skimage.color.rgb2gray(image))\n",
    "image_sobel_v = skimage.filters.sobel_v(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image_sobel <= skimage.filters.threshold_otsu(image_sobel), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_sobel_h >= skimage.filters.threshold_otsu(image_sobel_h), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_sobel_v <= skimage.filters.threshold_otsu(image_sobel_v), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the image with a Laplace filter\n",
    "image_laplace = skimage.filters.laplace(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_laplace, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_laplace <= skimage.filters.threshold_otsu(image_laplace), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar Cascades\n",
    "The following looks at Haar features and their use in tracking of human faces by use of a cascade classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video in\n",
    "cap = cv2.VideoCapture('face.mp4')\n",
    "\n",
    "# Create Haar cascade detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# Loop over frames in the video and apply cascade detector\n",
    "for i_frame in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    \n",
    "    # Get frame and convert to grayscale\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Detect faces and annotate the frame with a bounding box\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        # Detect eyes in the face and annotate with bounding boxes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    # Render the frame\n",
    "    cv2.imshow('img',frame)\n",
    "    cv2.waitKey(2)\n",
    "\n",
    "# Close everything once finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoG Features\n",
    "The utilises the Histogram of Gradients feature extractor on the given image. We can then look at varying the hyperparameters to observe the impact on retained details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HoG features and obtain both the vector and the HoG visualization image\n",
    "hog, hogvis = skimage.feature.hog(image, visualize=True)\n",
    "\n",
    "# Plot the original and the HoG rose plots\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(hogvis, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog, hogvis = skimage.feature.hog(image, pixels_per_cell=(32, 32), visualize=True)\n",
    "hog, hogvis2 = skimage.feature.hog(image, pixels_per_cell=(16, 16), visualize=True)\n",
    "hog, hogvis3 = skimage.feature.hog(image, pixels_per_cell=(2, 2), visualize=True)\n",
    "\n",
    "# Plot the various HoG results with differing cell sizes\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(hogvis, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(hogvis2, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(hogvis3, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}