{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I will simply build a classifier that detects the presence of a red ball or not in the training imagaes.\n",
    "    - First build classifier\n",
    "    - Then try to do the sliding window thing.\n",
    "    - I think the purpose of sliding window is so we know the new location of the ball. E.g. If we find ball in top right then move in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image   # https://www.pluralsight.com/guides/importing-image-data-into-numpy-arrays\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "# Official https://www.tensorflow.org/tutorials/images/cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dirs\n",
    "pos_img_dir = 'TrainingImages/positives/'\n",
    "neg_img_dir = 'TrainingImages/negatives/'\n",
    "\n",
    "# go through negatives\n",
    "neg_images = []\n",
    "neg_labels = np.zeros( len( os.listdir(neg_img_dir) ) )\n",
    "\n",
    "for filename in os.listdir(neg_img_dir):\n",
    "    neg_images.append(np.array(Image.open(neg_img_dir + filename))/255 )  # Normal\n",
    "\n",
    "print(np.shape(neg_images))\n",
    "\n",
    "# go through positives\n",
    "pos_images = []\n",
    "pos_labels = np.ones( len( os.listdir(pos_img_dir) ) )\n",
    "\n",
    "for filename in os.listdir(pos_img_dir):\n",
    "    pos_images.append(np.array(Image.open(pos_img_dir + filename))/255 ) \n",
    "\n",
    "print(np.shape(pos_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-938cd6547ac5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# With full colour images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'neg_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Now weve got data in array form we can split into test and train data?\n",
    "# With full colour images\n",
    "\n",
    "X = np.concatenate((neg_images, pos_images))\n",
    "y = np.concatenate((neg_labels, pos_labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=300,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Maybe TODO One-Hot-Encode CNN labels? Does it matter?\n",
    "#Prove test and train data is split correctly\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass CNN Architecture from \n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(51, 51, 3))) # Or input_shape=(X.shape[1:]) to get inshape\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(2))\n",
    "#model.add(layers.Dense(2)) # If activation function is used on last layer then accuracy will only be 0.9 not 0.99  \n",
    "# Keras Documentation:\n",
    "# activation: Activation function to use (see activations). \n",
    "# If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification CNN Architecture from \n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# TODO Try their imageGenerator and ensure it will recognise half spheres and that stuff\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(51, 51, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Only a single Conv layer\n",
    "# Rationale is that there are no higher levels or complicated features to the detection problem.\n",
    "# Probably detecting the ball as a solid object of red colour, nothing more complicated than that.\n",
    "\n",
    "model.add(layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))  # Prevent overfitting\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dave = model.predict(X_test)\n",
    "# compare with y_test in explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first image to classify\n",
    "\n",
    "import PacMan_functionality as PacMan\n",
    "\n",
    "# Initialise game\n",
    "global_cloud, spheres_collected = PacMan.startup_scene()\n",
    "# Create current camera position and angle\n",
    "position = np.zeros([3])\n",
    "angle = np.zeros([3])\n",
    "\n",
    "# Obtain image and associated maps\n",
    "image, map1, map2, map3, map4 = PacMan.project_pointcloud_image(global_cloud, angle, position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)\n",
    "np.shape(image)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict( np.array( [single_test,] )  ) # Correct syntax\n",
    "model.predict( np.array( [image[0:51,0:51,:],] )  )\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function sliding window\n",
    "# returns array of windows that I can classify at once\n",
    "def sliding_window( step_size, image ):\n",
    "    #image is (160, 240, 3)\n",
    "    #window is (51, 51, 3)\n",
    "    image_hight = image.shape[0] # 160\n",
    "    image_width = image.shape[1] # 240\n",
    "    window_size = 51\n",
    "    windows = []\n",
    "\n",
    "    for y in range(0, image_hight-window_size, step_size):   # Verticle?\n",
    "        for x in range (0, image_width-window_size, step_size):   #horizontal?\n",
    "            windows.append(image[y:y+window_size, x:x+window_size, :])\n",
    "\n",
    "    return np.array(windows) # Return windows as np array\n",
    "\n",
    "res = sliding_window(1, image)\n",
    "np.shape(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sliding_window(20, image)\n",
    "\n",
    "def confidence_threshold(prediction):\n",
    "    # Will return true if models confidence is above a threshold value\n",
    "    threshold = 0.02\n",
    "    if (prediction > threshold):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(len(test[:,0,0,0]))\n",
    "\n",
    "for i in range( len(test[:,0,0,0]) ):\n",
    "    \n",
    "    prediction = model.predict( np.array( [test[i,:,:,:],]) )\n",
    "\n",
    "    if (confidence_threshold(prediction)==False):\n",
    "        continue\n",
    "    else:\n",
    "        print(i)\n",
    "        print(prediction)\n",
    "        print(confidence_threshold(prediction))  \n",
    "        #print( str(prediction).format(1.0e-9) ) # Force scientific notation off\n",
    "        plt.figure(figsize=(4,2))\n",
    "        plt.imshow(test[i,:,:,:])    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a new CNN with the input data augmented so it will classify obscured spheres\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "#########################################################\n",
    "# With this the whole file structure had to be changed.\n",
    "# I dont want to obscure it, otherwise I wont know where the sphere is\n",
    "#########################################################\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.6,  #\n",
    "        height_shift_range=0.6, # Incresead these so theyre high so theyll know to classify sphere if only half a sphere is showing\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('TrainingImages/positives/positivePatch_304.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (51, 51, 3)\n",
    "x = x.reshape((1,) + x.shape)  # np array with shape (1, 51, 51, 3)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir='TrainingImages/test', save_prefix='pos', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(51, 51, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        width_shift_range=0.6,\n",
    "        height_shift_range=0.6,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.6,  #\n",
    "        height_shift_range=0.6, # Incresead these so theyre high so theyll know to classify sphere if only half a sphere is showing\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'TrainingImages/train',  # this is the target directory\n",
    "        target_size=(51, 51),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'TrainingImages/test',\n",
    "        target_size=(51, 51),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sliding_window(50, image)\n",
    "\n",
    "def confidence_threshold(prediction):\n",
    "    # Will return true if models confidence is above a threshold value\n",
    "    threshold = 0.02\n",
    "    if (prediction > threshold):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(len(test[:,0,0,0]))\n",
    "\n",
    "for i in range( len(test[:,0,0,0]) ):\n",
    "    \n",
    "    prediction = model.predict( np.array( [test[i,:,:,:],]) )\n",
    "\n",
    "    if (confidence_threshold(prediction)==False):\n",
    "        continue\n",
    "    else:\n",
    "        print(i)\n",
    "        print(prediction)\n",
    "        print(confidence_threshold(prediction))  \n",
    "        #print( str(prediction).format(1.0e-9) ) # Force scientific notation off\n",
    "        plt.figure(figsize=(4,2))\n",
    "        plt.imshow(test[i,:,:,:])    \n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}