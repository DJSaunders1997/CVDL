{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M77 Coursework: 3D \"Pac-Man\"\n",
    "The following coursework is designed to test multiple components of the module sylabus; including 3D geometry, object detection, feature extraction and image manipulation.\n",
    "\n",
    "Your task is to complete the below skeleton code to play a Pac-Man-esque game in 3D. You are allowed to utilise method discussed in the course, including feature extractors and deep learning approaches.\n",
    "\n",
    "The aim of the coursework is to step through a 3D pointcloud of the old PhD lab at Swansea University. Several large spheres have been placed within the space, it is your job to move through the pointcloud in an automated fashion, detecting the location of the sphere and moving to the predicted 3D location. If you land close enough to a sphere it will be captured and removed from the pointcloud. \n",
    "\n",
    "You will need to decide what kinds of feature you want to use, extract these features and train a classifier to detect the spheres within an image. You can then use the functionality provided in the PacMan_functionality.py module to obtain the XYZ coordinates of the pixel you predict to be a sphere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Hre we will do our usual imports. I would recommend numpy, scipy, skimage, matplotlib and sklearn. If you wish to utilise the pointcloud processing toolkit you can do that as described in the handout. We will want to import our PacMan_functionality module as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image   # https://www.pluralsight.com/guides/Importing-image-data-into-numpy-arrays\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO Sort out imports when CNN architecture is finished.\n",
    "# TODO replace with import keras then replace from imports\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PacMan_functionality as PacMan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game setup.\n",
    "This cell will initialise the game world and add all of our spheres to the world. Do not edit the code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call startup_scene() to load the initial game scene\n",
    "global_cloud, spheres_collected = PacMan.startup_scene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View our pointcloud if we want\n",
    "#v = pptk.viewer(global_cloud['Positions'], global_cloud['Colors']/255) # Fast, requires pptk\n",
    "#PacMan.show_point_cloud(global_cloud) # Slow, requires matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data: Positives and Negatives\n",
    "In the handout zip file there is a directory which contains numerous patches extracted from sample images. These patches are labelled as either containing a sphere or not. You may wish to use these to train a classifier for sphere detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training samples for both positive and negative patches\n",
    "\n",
    "# Define dirs\n",
    "pos_img_dir = 'TrainingImages/positives/'\n",
    "neg_img_dir = 'TrainingImages/negatives/'\n",
    "\n",
    "# go through negatives\n",
    "neg_images = []\n",
    "neg_labels = np.zeros( len( os.listdir(neg_img_dir) ) )\n",
    "\n",
    "for filename in os.listdir(neg_img_dir):\n",
    "    neg_images.append(np.array(Image.open(neg_img_dir + filename))/255 )  # Normal\n",
    "\n",
    "print(np.shape(neg_images))\n",
    "\n",
    "# go through positives\n",
    "pos_images = []\n",
    "pos_labels = np.ones( len( os.listdir(pos_img_dir) ) )\n",
    "\n",
    "for filename in os.listdir(pos_img_dir):\n",
    "    pos_images.append(np.array(Image.open(pos_img_dir + filename))/255 ) \n",
    "\n",
    "print(np.shape(pos_images))\n",
    "\n",
    "# Concatenate the patches into a 4D numpy array (S*H*W*C), and create a label vector (S)\n",
    "\n",
    "\n",
    "X = np.concatenate((neg_images, pos_images))\n",
    "y = np.concatenate((neg_labels, pos_labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, stratify=y, random_state=300,shuffle=True)\n",
    "\n",
    "#Prove test and train data is split correctly\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier on the samples, this may require feature extraction on the patches\n",
    "Depending on your desired apporach you may want to extract features on the training patches you have been given. These can then be used to train our desired classifier to detect the patches based not on the raw data, but on a representative feature descriptor. Several are talked about both in the lectures and labs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features - maybe, might not be needed with representation learning approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classification model to perform binary classification of the patch into whether it contains a sphere.\n",
    "\n",
    "# Architecture similar to Image Generator but without the augmentations\n",
    "# Binary Classification CNN Architecture from \n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# TODO Try their imageGenerator and ensure it will recognise half spheres and that stuff\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(51, 51, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(51, 51, 3)))   # Without this layer even the first sphere wouldnt be classified\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), input_shape=(51, 51, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))  # Prevent overfitting\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
    "\n",
    "model.save('Final_CNN.h5')    # Save model so it can be reloaded without retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just Load model for now\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('Final_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define my own functions that will be used\n",
    "sliding_windows,\n",
    "detect_spheres,\n",
    "move_to_sphere are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function sliding window\n",
    "# This function goes through windows in an image and returns the x,y coordinates of the start\n",
    "# of the windows containing spheres, and distance to sphere as a np array\n",
    "def sliding_window_classifier( step_size, image, depth ):\n",
    "    #image is (160, 240, 3)\n",
    "    #window is (51, 51, 3)\n",
    "    image_hight = image.shape[0] # 160\n",
    "    image_width = image.shape[1] # 240\n",
    "    window_size = 51\n",
    "    result = []\n",
    "\n",
    "    for y in range(0, image_hight-window_size, step_size): \n",
    "        for x in range (0, image_width-window_size, step_size):\n",
    "\n",
    "            window = image[y:y+window_size, x:x+window_size, :]\n",
    "\n",
    "            #Normaly you predict on an array of value, but here since we want the (x,y) coordinates this is easier\n",
    "            window = np.expand_dims(window, axis=0) # Adds first dimension to data (1,51,51,3) -> (1,51,51,3)\n",
    "            prediction = model.predict( np.array( window ) )\n",
    "            prediction = prediction[0][0] #  Unpack prediction [[1.]] -> 1\n",
    "\n",
    "            # Only want patches we are 99.9% sure contain spheres\n",
    "            if (prediction > 0.999):                \n",
    "                print(f'Depth: {depth[y+25, x+25]}, Prediction {prediction}')\n",
    "                plt.figure(figsize=(1,1))\n",
    "                plt.title('Image')\n",
    "                plt.imshow( window[0,:,:,:] )   \n",
    "        \n",
    "                # Add 'crosshair' to show middle pixel\n",
    "                ax=plt.gca() \n",
    "                ax.spines['left'].set_position('center')\n",
    "                ax.spines['bottom'].set_position('center')\n",
    "                ax.xaxis.set_ticks_position('bottom')\n",
    "                ax.yaxis.set_ticks_position('left')\n",
    "                plt.show()\n",
    "\n",
    "                # Spheres are always in the centre of the window.\n",
    "                # Middle depth is the depth of the pixel in the centre of the sphere and window.\n",
    "                middle_depth = depth[y+25, x+25]\n",
    "\n",
    "                # Need these to be returned so we can move to the closest sphere.\n",
    "                # x, y are now the coordinates of the centre of the sphere.\n",
    "                result.append( (x+25, y+25, middle_depth) )\n",
    "\n",
    "    # Results are np array with columns: x, y, depth\n",
    "    # If length is 0 then no spheres were found\n",
    "    return np.asarray(result)   \n",
    "\n",
    "# Not necessary but nicely prints out the current viewpoints\n",
    "def visualise_maps(image, mapx, mapy, mapz, depth):\n",
    "    # Inputs can be full 160x240 or 51x51 in size\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(20,3))\n",
    "\n",
    "    ax[0].set_title('image')\n",
    "    im0 = ax[0].imshow(image)\n",
    "    #fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "    ax[1].set_title('mapx')\n",
    "    im1 = ax[1].imshow(mapx, cmap='bwr')\n",
    "    fig.colorbar(im1, ax=ax[1])\n",
    "\n",
    "    ax[2].set_title('mapy')\n",
    "    im2 = ax[2].imshow(mapy, cmap='bwr')\n",
    "    fig.colorbar(im2, ax=ax[2])\n",
    "\n",
    "    ax[3].set_title('mapz')\n",
    "    im3 = ax[3].imshow(mapz, cmap='bwr')\n",
    "    fig.colorbar(im3, ax=ax[3])\n",
    "\n",
    "    ax[4].set_title('depth')\n",
    "    im4 = ax[4].imshow(depth, cmap='bwr')\n",
    "    fig.colorbar(im4, ax=ax[4])\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise our starting point in the game and get our first view into the scene\n",
    "We should start the game at a position of XYZ = [0, 0, 0] and a camera angle of [0, 0, 0]. These variables can be updated once we find a sphere, or rotated when we don't find a sphere. We can then get our first image projected to the camera plane to start our game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise position and angle variable \n",
    "position = np.zeros([3])\n",
    "angle = np.zeros([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image, XYZ maps and depth map of the current viewpoint into the scene\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Perform our loop, in which we will perform pixel-wise prediction on binary class label and then perform the correct action based on detection of spheres.\n",
    "This will be the main bulk of your implementation, utilising the feature descriptors and trained models from the above cells. In each loop of the program we will want to:\n",
    "-  Get current view into the scene\n",
    "-  Extract patches from the scene\n",
    "-  Extract features on the patches\n",
    "-  Use the pretrained model to obtain class prediction probabilities\n",
    "-  Identify if a sphere has been found in the scene\n",
    "  -  If so, find the mapped XYZ location, move there and update the scene\n",
    "  -  If not, rotate the camera in a bid to find the sphere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start time:')\n",
    "print(datetime.now().strftime('%H:%M:%S') ) # Used to time the execution of the program.\n",
    "\n",
    "window_step_size = 10   # How big the steps are between windows\n",
    "rotation_angle = np.pi*1/6 # will rotate π/6 or 30°\n",
    "\n",
    "while not np.all(spheres_collected): # While there are spheres to find\n",
    "    # Get current image from viewpoint\n",
    "    print('Getting maps.... may take a while')\n",
    "    image, mapx, mapy, mapz, depth = PacMan.project_pointcloud_image(global_cloud, angle, position)\n",
    "    visualise_maps(image, mapx, mapy, mapz, depth)\n",
    "\n",
    "    # Extract patches from the scene\n",
    "    # Extract features from the patches    \n",
    "    # Predict the probability of a pixel being a sphere, based on the patch\n",
    "    # Use probabilities to find sphere coordinates in 3D\n",
    "    sphere_windows = sliding_window_classifier(window_step_size, image, depth)\n",
    "\n",
    "    # Update camera appropriately\n",
    "    if ( len(sphere_windows) == 0):\n",
    "        #rotate\n",
    "        print('### No spheres found, rotating')\n",
    "        angle = angle - np.asarray([0, rotation_angle, 0])   # numpy - is an elementwise operation \n",
    "\n",
    "    else:   # Spheres have been detected\n",
    "        # Find the location of the window with lowest depth, which will show the closest sphere\n",
    "        # sphere_windows has columns (x, y, depth)\n",
    "        min_index = np.argmin( sphere_windows[:,2] )# Get the index of the closest sphere \n",
    "        x = int( sphere_windows[min_index, 0] )     # Get x location of start of sphere\n",
    "        y = int( sphere_windows[min_index, 1] )    \n",
    "\n",
    "        # Get spacial coordinates of new sphere\n",
    "        newx = mapx[y, x] # I want Y, X not X, Y \n",
    "        newy = mapy[y, x] \n",
    "        newz = mapz[y, x] \n",
    "\n",
    "        # Move position and update scene\n",
    "        print(f'I am at position {position}')\n",
    "        print(f'I have found {np.sum(spheres_collected)} out of {len(spheres_collected)} spheres!\\n')\n",
    "\n",
    "        position = np.asarray([newx, newy, newz])\n",
    "        print(f'I am now at position {position}')\n",
    "        \n",
    "        # Update scene\n",
    "        global_cloud, spheres_collected = PacMan.update_scene(position, spheres_collected);\n",
    "        print(f'I have found {np.sum(spheres_collected)} out of {len(spheres_collected)} spheres!\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}